{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79a9fe1-ec0d-43de-9dc8-490071ccde41",
   "metadata": {
    "papermill": {
     "duration": 0.027582,
     "end_time": "2024-06-28T08:26:25.590047",
     "exception": false,
     "start_time": "2024-06-28T08:26:25.562465",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set\n"
     ]
    }
   ],
   "source": [
    "# Setting parameters, replace with defaults when using a master notebook\n",
    "\n",
    "countrycode = 'default'\n",
    "countryname = 'default'\n",
    "\n",
    "print(\"Parameters set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6603f705",
   "metadata": {
    "papermill": {
     "duration": 0.015379,
     "end_time": "2024-06-28T08:26:25.611664",
     "exception": false,
     "start_time": "2024-06-28T08:26:25.596285",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "countrycode = \"AGO\"\n",
    "countryname = \"Angola\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686584ea",
   "metadata": {
    "papermill": {
     "duration": 0.006157,
     "end_time": "2024-06-28T08:26:25.621660",
     "exception": false,
     "start_time": "2024-06-28T08:26:25.615503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0e1cdf",
   "metadata": {
    "papermill": {
     "duration": 3.33493,
     "end_time": "2024-06-28T08:26:28.960953",
     "exception": false,
     "start_time": "2024-06-28T08:26:25.626023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import xy\n",
    "from rasterio.transform import Affine\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "from exactextract import exact_extract\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "import statsmodels.api as sm\n",
    "import pyreadr\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48cb26",
   "metadata": {
    "papermill": {
     "duration": 0.006058,
     "end_time": "2024-06-28T08:26:28.973640",
     "exception": false,
     "start_time": "2024-06-28T08:26:28.967582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca5a914",
   "metadata": {
    "papermill": {
     "duration": 8.569215,
     "end_time": "2024-06-28T08:26:37.546513",
     "exception": false,
     "start_time": "2024-06-28T08:26:28.977298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/vastic/Library/Mobile Documents/com~apple~CloudDocs/Desktop/python-run/ruralntl/sub-saharan/AGO/AGO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Setting the working directory to the country's subfolder\u001b[39;00m\n\u001b[1;32m      4\u001b[0m base_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcountrycode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the rds data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m rds_file \u001b[38;5;241m=\u001b[39m countrycode \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ntl_pop.rds\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/vastic/Library/Mobile Documents/com~apple~CloudDocs/Desktop/python-run/ruralntl/sub-saharan/AGO/AGO'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Setting the working directory to the country's subfolder\n",
    "base_path = os.getcwd()\n",
    "os.chdir(os.path.join(base_path, countrycode))\n",
    "\n",
    "# Load the rds data\n",
    "rds_file = countrycode + '_ntl_pop.rds'\n",
    "results = pyreadr.read_r(rds_file)\n",
    "# Extract the data frame from the result\n",
    "data = results[None]  # Extracts the first (and usually only) dataframe from the result\n",
    "\n",
    "\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# Debugging: Check the first few rows of the data\n",
    "print(\"Data preview before 'haslight' column creation:\")\n",
    "print(data.head(100))\n",
    "\n",
    "# Create a binary 'haslight' column based on 'ntl' values\n",
    "data['haslight'] = (data['ntl'] > 0).astype(int)\n",
    "\n",
    "# Debugging: Check the first few rows after 'haslight' column creation\n",
    "print(\"Data preview after 'haslight' column creation:\")\n",
    "print(data.head(100))\n",
    "\n",
    "data.drop(columns=['ntl', 'pop'], inplace=True)\n",
    "print(\"Columns 'ntl' and 'pop' dropped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae648d",
   "metadata": {
    "papermill": {
     "duration": 0.003822,
     "end_time": "2024-06-28T08:26:37.557745",
     "exception": false,
     "start_time": "2024-06-28T08:26:37.553923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert DataFrame to GeoDataFrame\n",
    "\n",
    "Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de8e61",
   "metadata": {
    "papermill": {
     "duration": 7.19632,
     "end_time": "2024-06-28T08:26:44.758891",
     "exception": false,
     "start_time": "2024-06-28T08:26:37.562571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data['x'], data['y']))\n",
    "print(\"Converted to GeoDataFrame\")\n",
    "end_time = time.time()\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de3016-a92b-4bc5-aebf-a90aa3ccec3f",
   "metadata": {
    "papermill": {
     "duration": 183.1096,
     "end_time": "2024-06-28T08:29:47.883794",
     "exception": false,
     "start_time": "2024-06-28T08:26:44.774194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01c113-1d70-46a0-b20b-45bd9528bf3f",
   "metadata": {
    "papermill": {
     "duration": 24.618845,
     "end_time": "2024-06-28T08:30:12.510177",
     "exception": false,
     "start_time": "2024-06-28T08:29:47.891332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = data.set_index(['y', 'x']).to_xarray()\n",
    "ds.haslight.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85cf11f-584a-4c23-8eb6-a7fa6192a91c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T08:30:12.526920Z",
     "iopub.status.busy": "2024-06-28T08:30:12.526243Z",
     "iopub.status.idle": "2024-06-28T08:30:12.978798Z",
     "shell.execute_reply": "2024-06-28T08:30:12.976587Z"
    },
    "papermill": {
     "duration": 0.465704,
     "end_time": "2024-06-28T08:30:12.983379",
     "exception": false,
     "start_time": "2024-06-28T08:30:12.517675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute: 0.01\n"
     ]
    }
   ],
   "source": [
    "# transform data array and write it to a GeoTIFF \n",
    "\n",
    "start_time = time.time()\n",
    "data_array = ds.haslight.values[::-1]\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "pixel_size = 15 / 3600 \n",
    "transform = Affine.translation(xmin - pixel_size / 2, ymax + pixel_size / 2) * Affine.scale(pixel_size, -pixel_size)#from_origin(xmin, ymax, pixel_size, pixel_size)\n",
    "with rasterio.open(\n",
    "    'haslight.tif',\n",
    "    'w', \n",
    "    driver='GTiff',\n",
    "    height=data_array.shape[0],\n",
    "    width=data_array.shape[1],\n",
    "    count=1,\n",
    "    dtype=data_array.dtype,\n",
    "    crs='EPSG:4326',\n",
    "    transform=transform,\n",
    ") as tiff:\n",
    "    tiff.write(data_array, 1)\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6f934",
   "metadata": {
    "papermill": {
     "duration": 0.006886,
     "end_time": "2024-06-28T08:30:12.996290",
     "exception": false,
     "start_time": "2024-06-28T08:30:12.989404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Shapefile\n",
    "\n",
    "This takes some time, depending on file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af4b52f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T08:30:13.006855Z",
     "iopub.status.busy": "2024-06-28T08:30:13.006422Z",
     "iopub.status.idle": "2024-06-28T08:33:35.130863Z",
     "shell.execute_reply": "2024-06-28T08:33:35.129555Z"
    },
    "papermill": {
     "duration": 202.133329,
     "end_time": "2024-06-28T08:33:35.133932",
     "exception": false,
     "start_time": "2024-06-28T08:30:13.000603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "grid3_AGO/GRID3_AGO_-_Settlement_Extents_v1.1.shp\n",
      "...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers for each settlement type before geometries applied:\n",
      "type\n",
      "Hamlet                   563715\n",
      "Small Settlement Area     18132\n",
      "Built-up Area               197\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet: 0 geometries removed (0.00%)\n",
      "Small Settlement Area: 0 geometries removed (0.00%)\n",
      "Built-up Area: 0 geometries removed (0.00%)\n",
      "Invalid and empty geometries removed\n",
      "Numbers for each settlement type AFTER geometries applied:\n",
      "type\n",
      "Hamlet                   563715\n",
      "Small Settlement Area     18132\n",
      "Built-up Area               197\n",
      "Name: count, dtype: int64\n",
      "Time to execute: 3.37 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Go to the grid3 subfolder\n",
    "grid3_folder = 'grid3_' + countrycode\n",
    "\n",
    "# Find the shapefile in the directory\n",
    "shapefile = None\n",
    "\n",
    "#for countrynames with several words\n",
    "first_word_countryname = countryname.split()[0]\n",
    "\n",
    "# shapefile should contain the ending .shp, and the countrycode or countryname (at least the first word), as grid3 data tends to do\n",
    "for file in os.listdir(grid3_folder):\n",
    "    if file.endswith('.shp') and (countrycode in file or first_word_countryname in file):\n",
    "        shapefile = file\n",
    "        break\n",
    "\n",
    "# Check if the shapefile was found and if it contains the countrycode\n",
    "if shapefile is None:\n",
    "    print('No shapefile found in the directory ending with .shp')\n",
    "\n",
    "# Print the shapefile path\n",
    "shapefile_path = os.path.join(grid3_folder, shapefile)\n",
    "\n",
    "print(\"Loading\")\n",
    "print(shapefile_path)\n",
    "print(\"...\")\n",
    "\n",
    "settlements = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Ensure spelling is Built-up and not Built-Up (e.g. Kenya data)\n",
    "settlements['type'] = settlements['type'].replace('Built-Up Area', 'Built-up Area')\n",
    "\n",
    "#checking total of settlements per type\n",
    "settlement_type_counts = settlements['type'].value_counts()\n",
    "print(\"Numbers for each settlement type before geometries applied:\")\n",
    "print(settlement_type_counts)\n",
    "\n",
    "# Count the number of geometries for each settlement type before removal\n",
    "type_counts_before = settlements['type'].value_counts()\n",
    "\n",
    "# Ensure all geometries are valid\n",
    "settlements['geometry'] = settlements['geometry'].astype(object).apply(lambda geom: geom if geom.is_valid else geom.buffer(0))\n",
    "\n",
    "# Remove empty geometries\n",
    "settlements = settlements[~settlements['geometry'].is_empty]\n",
    "\n",
    "# Count the number of geometries for each settlement type after removal\n",
    "type_counts_after = settlements['type'].value_counts()\n",
    "\n",
    "# Calculate the number and proportion of geometries removed for each settlement type\n",
    "for settlement_type in type_counts_before.index:\n",
    "    count_before = type_counts_before[settlement_type]\n",
    "    count_after = type_counts_after.get(settlement_type, 0)\n",
    "    count_removed = count_before - count_after\n",
    "    proportion_removed = count_removed / count_before\n",
    "    print(f\"{settlement_type}: {count_removed} geometries removed ({proportion_removed:.2%})\")\n",
    "print(\"Invalid and empty geometries removed\")\n",
    "print(\"Numbers for each settlement type AFTER geometries applied:\")\n",
    "settlement_type_counts = settlements['type'].value_counts()\n",
    "print(settlement_type_counts)\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d289d9",
   "metadata": {
    "papermill": {
     "duration": 0.009424,
     "end_time": "2024-06-28T08:33:35.149406",
     "exception": false,
     "start_time": "2024-06-28T08:33:35.139982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculate zonal statistics\n",
    "\n",
    "In this step, simply check if there is NTL (0/1), then for each settlement calculate what percentage of the polygon has NTL. \n",
    "\n",
    "This cell takes some time, with Sudan, around 10min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef34f92b-b5e2-411d-88af-e922456cd64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T08:33:35.163746Z",
     "iopub.status.busy": "2024-06-28T08:33:35.163122Z",
     "iopub.status.idle": "2024-06-28T08:38:53.748678Z",
     "shell.execute_reply": "2024-06-28T08:38:53.747749Z"
    },
    "papermill": {
     "duration": 318.602392,
     "end_time": "2024-06-28T08:38:53.758701",
     "exception": false,
     "start_time": "2024-06-28T08:33:35.156309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted percentages added to GeoDataFrame\n",
      "Execution time: 5.309622653325399 minutes\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "from exactextract import exact_extract\n",
    "import time\n",
    "\n",
    "# Start time for execution time calculation\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the path to your raster data\n",
    "raster_path = 'haslight.tif'\n",
    "\n",
    "# Open the raster and convert it to binary (has light or has no light)\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(1)  # Read the first band\n",
    "    binary_raster_data = (raster_data > 0).astype(int)  # Convert to binary\n",
    "\n",
    "    # Write the binary raster to a new file (optional, can also be done in-memory)\n",
    "    binary_raster_path = 'binary_haslight.tif'\n",
    "    profile = src.profile\n",
    "    with rasterio.open(binary_raster_path, 'w', **profile) as dst:\n",
    "        dst.write(binary_raster_data, 1)\n",
    "\n",
    "# Perform the exact extraction using the binary raster\n",
    "settlements_updated = settlements.copy()\n",
    "results = exact_extract(binary_raster_path, settlements, [\"mean\"])\n",
    "\n",
    "# Add the weighted mean light coverage to the settlements GeoDataFrame\n",
    "settlements_updated['NTL_weighted_percentage'] = [feature['properties']['mean'] * 100 for feature in results]\n",
    "print(\"Weighted percentages added to GeoDataFrame\")\n",
    "\n",
    "# Calculate the execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf352a",
   "metadata": {
    "papermill": {
     "duration": 0.00641,
     "end_time": "2024-06-28T08:38:53.772485",
     "exception": false,
     "start_time": "2024-06-28T08:38:53.766075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be29291-bef7-4d0b-876e-2627b5fab348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T08:38:53.787021Z",
     "iopub.status.busy": "2024-06-28T08:38:53.786439Z",
     "iopub.status.idle": "2024-06-28T08:39:00.665109Z",
     "shell.execute_reply": "2024-06-28T08:39:00.663907Z"
    },
    "papermill": {
     "duration": 6.891264,
     "end_time": "2024-06-28T08:39:00.669119",
     "exception": false,
     "start_time": "2024-06-28T08:38:53.777855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved, all done.\n",
      "Time to execute: 0.11 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "csv_name = countrycode + '_grid3_with_ntl_percentage.csv'\n",
    "settlements_updated.drop(columns=['geometry']).to_csv(csv_name, index=False)\n",
    "print(\"CSV saved, all done.\")\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0423a4",
   "metadata": {
    "papermill": {
     "duration": 0.008574,
     "end_time": "2024-06-28T08:39:00.685273",
     "exception": false,
     "start_time": "2024-06-28T08:39:00.676699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculate key stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af18db85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T08:39:00.701360Z",
     "iopub.status.busy": "2024-06-28T08:39:00.700656Z",
     "iopub.status.idle": "2024-06-28T08:39:02.523416Z",
     "shell.execute_reply": "2024-06-28T08:39:02.522053Z"
    },
    "papermill": {
     "duration": 1.834396,
     "end_time": "2024-06-28T08:39:02.526144",
     "exception": false,
     "start_time": "2024-06-28T08:39:00.691748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKey stats Angolan\u001b[0m\n",
      "Something wrong with 0 entries\n",
      " \n",
      "\u001b[1mOverview all settlements\u001b[0m\n",
      "Proportion nighttime light: 1.35%\n",
      "Proportion monitorable: 0.93%\n",
      " \n",
      "\u001b[1mOverview built-up areas\u001b[0m\n",
      "Total number of built-up areas: 197\n",
      "Proportion nighttime light > 0: 4.06%\n",
      "Median NTL for settlements with any NTL: 4562.99%\n",
      "Proportion monitorable: 2.03%\n",
      " \n",
      "\u001b[1mOverview small settlements\u001b[0m\n",
      "Total number of small settlement areas: 18132\n",
      "Proportion nighttime light: 2.22%\n",
      "Median NTL for settlements with any NTL: 3671.04%\n",
      "Proportion monitorable: 0.84%\n",
      " \n",
      "\u001b[1mOverview hamlets\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of hamlets: 563715\n",
      "Proportion nighttime light: 1.32%\n",
      "Median NTL for settlements with any NTL: 9731.78%\n",
      "Proportion monitorable: 0.93%\n",
      " \n",
      "\u001b[1mOverview monitorable population\u001b[0m\n",
      "Proportion of population that is monitorable (living in settlements with more than 50% NTL): 3.44%\n",
      "Proportion of population that lives in settlements with any NTL): 5.78%\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the CSV file\n",
    "df = pd.read_csv(csv_name)\n",
    "\n",
    "print(f\"\\033[1mKey stats {countryname}n\\033[0m\")\n",
    "\n",
    "# Calculate 'something_wrong' (should be 0)\n",
    "#something_wrong = (df['NTL_weighted_percentage'] > 100).sum()\n",
    "#print(f\"Number of rows where there is something wrong with 'NTL_weighted_percentage': {something_wrong}\")\n",
    "something_wrong = (df['NTL_weighted_percentage'] > 100).sum()\n",
    "print(f\"Something wrong with {something_wrong} entries\")\n",
    "      \n",
    "print(\" \")\n",
    "# Calculate 'settl_ntl_perc'\n",
    "print(\"\\033[1mOverview all settlements\\033[0m\")\n",
    "settl_ntl_perc = (df['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {settl_ntl_perc:.2%}\")\n",
    "settl_monit_perc = (df['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {settl_monit_perc:.2%}\")\n",
    "anyntl = df[df['NTL_weighted_percentage'] > 0]\n",
    "all_median_any = anyntl['NTL_weighted_percentage'].median()\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview built-up areas\\033[0m\")\n",
    "# Calculate 'built_up_perc'\n",
    "df_built_up = df[df['type'] == 'Built-up Area']\n",
    "#Get the total number of built-up areas; shape gives tuple of dimensions\n",
    "print(f\"Total number of built-up areas: {df_built_up.shape[0]}\")\n",
    "built_ntl_perc = (df_built_up['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light > 0: {built_ntl_perc:.2%}\")\n",
    "\n",
    "#median ntl coverage of all the settlements that have at least some NTL\n",
    "anyntl = df_built_up[df_built_up['NTL_weighted_percentage'] > 0]\n",
    "built_median_any = anyntl['NTL_weighted_percentage'].median()\n",
    "print(f\"Median NTL for settlements with any NTL: {built_median_any:.2%}\")\n",
    "built_monit_perc = (df_built_up['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {built_monit_perc:.2%}\")\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview small settlements\\033[0m\")\n",
    "# Calculate 'small_settl_perc'\n",
    "df_small_set = df[df['type'] == 'Small Settlement Area']\n",
    "print(f\"Total number of small settlement areas: {df_small_set.shape[0]}\")\n",
    "smallset_ntl_perc = (df_small_set['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {smallset_ntl_perc:.2%}\")\n",
    "#median ntl coverage of all the settlements that have at least some NTL\n",
    "anyntl = df_small_set[df_small_set['NTL_weighted_percentage'] > 0]\n",
    "small_median_any = anyntl['NTL_weighted_percentage'].median()\n",
    "print(f\"Median NTL for settlements with any NTL: {small_median_any:.2%}\")\n",
    "smallset_monit_perc = (df_small_set['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {smallset_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview hamlets\\033[0m\")\n",
    "# Calculate 'hamlets_perc'\n",
    "df_hamlet = df[df['type'] == 'Hamlet']\n",
    "print(f\"Total number of hamlets: {df_hamlet.shape[0]}\")\n",
    "haml_ntl_perc = (df_hamlet['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {haml_ntl_perc:.2%}\")\n",
    "#median ntl coverage of all the settlements that have at least some NTL\n",
    "anyntl = df_hamlet[df_hamlet['NTL_weighted_percentage'] > 0]\n",
    "hamlet_median_any = anyntl['NTL_weighted_percentage'].median()\n",
    "print(f\"Median NTL for settlements with any NTL: {hamlet_median_any:.2%}\")\n",
    "haml_monit_perc = (df_hamlet['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {haml_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview monitorable population\\033[0m\")\n",
    "#settlements with more than 50% ntl\n",
    "df_mont = df[df['NTL_weighted_percentage'] > 50]\n",
    "monitorable_pop = df_mont['pop_un_adj'].sum()/df['pop_un_adj'].sum()\n",
    "\n",
    "print(f\"Proportion of population that is monitorable (living in settlements with more than 50% NTL): {monitorable_pop:.2%}\")\n",
    "\n",
    "#settlements with any ntl\n",
    "df_anyntl = df[df['NTL_weighted_percentage'] > 0]\n",
    "pop_anyntl = df_anyntl['pop_un_adj'].sum()/df['pop_un_adj'].sum()\n",
    "\n",
    "print(f\"Proportion of population that lives in settlements with any NTL): {pop_anyntl:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19da56-6c0d-4bd3-bed9-d0804a39c363",
   "metadata": {
    "papermill": {
     "duration": 0.0074,
     "end_time": "2024-06-28T08:39:02.544491",
     "exception": false,
     "start_time": "2024-06-28T08:39:02.537091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Calculate 80% threshold to have any nighttime light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efffe7a3-f798-4a07-99c0-13a65071aef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T08:39:02.559972Z",
     "iopub.status.busy": "2024-06-28T08:39:02.559125Z",
     "iopub.status.idle": "2024-06-28T08:39:07.395374Z",
     "shell.execute_reply": "2024-06-28T08:39:07.394066Z"
    },
    "papermill": {
     "duration": 4.846583,
     "end_time": "2024-06-28T08:39:07.398749",
     "exception": false,
     "start_time": "2024-06-28T08:39:02.552166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.071705\n",
      "         Iterations 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                any_ntl   No. Observations:               581323\n",
      "Model:                          Logit   Df Residuals:                   581321\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Fri, 28 Jun 2024   Pseudo R-squ.:               3.532e-06\n",
      "Time:                        10:39:07   Log-Likelihood:                -41684.\n",
      "converged:                       True   LL-Null:                       -41684.\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.5874\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.2884      0.011   -377.895      0.000      -4.311      -4.266\n",
      "pop_un_adj  1.543e-07   2.18e-07      0.709      0.478   -2.72e-07    5.81e-07\n",
      "==============================================================================\n",
      "The population threshold for 80% likelihood of having any NTL is approximately 14472110.7807796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(csv_name)\n",
    "\n",
    "# Create the 'any ntl' column, which just looks at whether there is any NTL in the settlement\n",
    "df['any_ntl'] = df['NTL_weighted_percentage'] > 0\n",
    "\n",
    "# Check for missing or infinite values in 'pop_un_adj'\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "# Drop rows with missing values\n",
    "df = df.dropna(subset=['pop_un_adj'])\n",
    "\n",
    "# Ensure there is variation in 'pop_un_adj' and 'any_ntl'\n",
    "if df['pop_un_adj'].nunique() <= 1 or df['any_ntl'].nunique() <= 1:\n",
    "    print(\"Insufficient variation in 'pop_un_adj' or 'any_ntl'. Setting threshold_anyntl to NaN.\")\n",
    "    threshold_anyntl = np.nan\n",
    "else:\n",
    "    try:\n",
    "        # Prepare the data for logistic regression\n",
    "        X = df['pop_un_adj']\n",
    "        y = df['any_ntl'].astype(int)  # Convert boolean to int (0 or 1)\n",
    "\n",
    "        # Add a small constant to avoid singular matrix\n",
    "        X = X + 1e-6\n",
    "\n",
    "        # Add a constant to the model (intercept)\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # Fit the logistic regression model\n",
    "        model = sm.Logit(y, X)\n",
    "        result = model.fit()\n",
    "\n",
    "        # Print the summary of the model\n",
    "        print(result.summary())\n",
    "\n",
    "        # Define the function to calculate the probability\n",
    "        def calculate_probability(population, model):\n",
    "            logit = model.params['const'] + model.params['pop_un_adj'] * population\n",
    "            return 1 / (1 + np.exp(-logit))\n",
    "\n",
    "        # Find the population threshold for 80% probability\n",
    "        population_range = np.linspace(df['pop_un_adj'].min(), df['pop_un_adj'].max(), 1000)\n",
    "        probabilities = [calculate_probability(pop, result) for pop in population_range]\n",
    "\n",
    "        # Find the population where the probability is closest to 0.8\n",
    "        threshold_anyntl = population_range[np.argmin(np.abs(np.array(probabilities) - 0.8))]\n",
    "        print(f\"The population threshold for 80% likelihood of having any NTL is approximately {threshold_anyntl}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}. Setting threshold_anyntl to NaN.\")\n",
    "        threshold_anyntl = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0e501-7883-4ff2-bd28-2f7e4dd40ef6",
   "metadata": {
    "papermill": {
     "duration": 0.007781,
     "end_time": "2024-06-28T08:39:07.414531",
     "exception": false,
     "start_time": "2024-06-28T08:39:07.406750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# save stats to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dafea3cc-6548-4053-baf6-44f210328350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T08:39:07.430171Z",
     "iopub.status.busy": "2024-06-28T08:39:07.429756Z",
     "iopub.status.idle": "2024-06-28T08:39:07.443311Z",
     "shell.execute_reply": "2024-06-28T08:39:07.441987Z"
    },
    "papermill": {
     "duration": 0.024246,
     "end_time": "2024-06-28T08:39:07.446525",
     "exception": false,
     "start_time": "2024-06-28T08:39:07.422279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries\n",
    "stats = [\n",
    "    {\"type\": \"Error\", \"what\": \"Settlements with over 100% NTL\", \"value\": something_wrong},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Total number\", \"value\": len(df)},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Proportion NTL\", \"value\": f\"{settl_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Proportion monitorable\", \"value\": f\"{settl_monit_perc:.2%}\"},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Median size NTL settlement\", \"value\": f\"{all_median_any}\"},\n",
    "\n",
    "\n",
    "    {\"type\": \"Built-up\", \"what\": \"Total number\", \"value\": df_built_up.shape[0]},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Proportion NTL\", \"value\": f\"{built_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Median NTL value for any NTL\", \"value\": f\"{built_median_any}\"},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Proportion monitorable\", \"value\": f\"{built_monit_perc:.2%}\"},\n",
    "\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Total number\", \"value\": df_small_set.shape[0]},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Proportion NTL\", \"value\": f\"{smallset_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Median NTL value for any NTL\", \"value\": f\"{small_median_any}\"},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Proportion monitorable\", \"value\": f\"{smallset_monit_perc:.2%}\"},\n",
    "\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Total number\", \"value\": df_hamlet.shape[0]},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Proportion NTL\", \"value\": f\"{haml_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Median NTL value for any NTL\", \"value\": f\"{hamlet_median_any}\"},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Proportion monitorable\", \"value\": f\"{haml_monit_perc:.2%}\"},\n",
    "\n",
    "    {\"type\": \"Population\", \"what\": \"Proportion living in settlements with any NTL\", \"value\": f\"{pop_anyntl:.2%}\"},\n",
    "    {\"type\": \"Population\", \"what\": \"Proportion living in monitorable settlements\", \"value\": f\"{monitorable_pop:.2%}\"},\n",
    "    {\"type\": \"Threshold NTL\", \"what\": \"Threshold 0.8 likelihood of any NTL in a settlement\", \"value\": f\"{threshold_anyntl}\"},\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df_output = pd.DataFrame(stats)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = 'overview_key_stats.csv'\n",
    "df_output.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Data saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 765.799147,
   "end_time": "2024-06-28T08:39:10.183848",
   "environment_variables": {},
   "exception": null,
   "input_path": "0_country-level-analysis-parametrized.ipynb",
   "output_path": "output_AGO.ipynb",
   "parameters": {
    "countrycode": "AGO",
    "countryname": "Angola"
   },
   "start_time": "2024-06-28T08:26:24.384701",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
