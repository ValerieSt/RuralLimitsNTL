{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79a9fe1-ec0d-43de-9dc8-490071ccde41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:16.149964Z",
     "iopub.status.busy": "2024-06-26T16:12:16.149555Z",
     "iopub.status.idle": "2024-06-26T16:12:16.161185Z",
     "shell.execute_reply": "2024-06-26T16:12:16.160238Z"
    },
    "papermill": {
     "duration": 0.023068,
     "end_time": "2024-06-26T16:12:16.164175",
     "exception": false,
     "start_time": "2024-06-26T16:12:16.141107",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set\n"
     ]
    }
   ],
   "source": [
    "# Setting parameters, replace with defaults when using a master notebook\n",
    "\n",
    "countrycode = 'default'\n",
    "countryname = 'default'\n",
    "\n",
    "print(\"Parameters set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c9abbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:16.174583Z",
     "iopub.status.busy": "2024-06-26T16:12:16.174344Z",
     "iopub.status.idle": "2024-06-26T16:12:16.178721Z",
     "shell.execute_reply": "2024-06-26T16:12:16.177175Z"
    },
    "papermill": {
     "duration": 0.012771,
     "end_time": "2024-06-26T16:12:16.181466",
     "exception": false,
     "start_time": "2024-06-26T16:12:16.168695",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "countrycode = \"AGO\"\n",
    "countryname = \"Angola\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686584ea",
   "metadata": {
    "papermill": {
     "duration": 0.003709,
     "end_time": "2024-06-26T16:12:16.189626",
     "exception": false,
     "start_time": "2024-06-26T16:12:16.185917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0e1cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:16.198691Z",
     "iopub.status.busy": "2024-06-26T16:12:16.198314Z",
     "iopub.status.idle": "2024-06-26T16:12:18.331798Z",
     "shell.execute_reply": "2024-06-26T16:12:18.330625Z"
    },
    "papermill": {
     "duration": 2.141554,
     "end_time": "2024-06-26T16:12:18.334668",
     "exception": false,
     "start_time": "2024-06-26T16:12:16.193114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.mask import mask\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "from exactextract import exact_extract\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48cb26",
   "metadata": {
    "papermill": {
     "duration": 0.003876,
     "end_time": "2024-06-26T16:12:18.342725",
     "exception": false,
     "start_time": "2024-06-26T16:12:18.338849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca5a914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:18.352052Z",
     "iopub.status.busy": "2024-06-26T16:12:18.351741Z",
     "iopub.status.idle": "2024-06-26T16:12:19.981627Z",
     "shell.execute_reply": "2024-06-26T16:12:19.980584Z"
    },
    "papermill": {
     "duration": 1.636909,
     "end_time": "2024-06-26T16:12:19.984229",
     "exception": false,
     "start_time": "2024-06-26T16:12:18.347320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Binary created\n",
      "Time to execute: 0.03\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Setting the working directory to the country's subfolder\n",
    "base_path = os.getcwd()\n",
    "os.chdir(os.path.join(base_path, countrycode))\n",
    "\n",
    "# Load the CSV data\n",
    "csv_file = countrycode + '_ntl_pop.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# Create a binary 'haslight' column and drop the 'ntl' and 'pop' columns\n",
    "data['haslight'] = (data['ntl'] > 0).astype(int)\n",
    "data.drop(columns=['ntl', 'pop'], inplace=True)\n",
    "print(\"Binary created\")\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae648d",
   "metadata": {
    "papermill": {
     "duration": 0.004488,
     "end_time": "2024-06-26T16:12:20.027256",
     "exception": false,
     "start_time": "2024-06-26T16:12:20.022768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert DataFrame to GeoDataFrame\n",
    "\n",
    "Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7de8e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:20.036548Z",
     "iopub.status.busy": "2024-06-26T16:12:20.036304Z",
     "iopub.status.idle": "2024-06-26T16:12:22.810444Z",
     "shell.execute_reply": "2024-06-26T16:12:22.808368Z"
    },
    "papermill": {
     "duration": 2.782815,
     "end_time": "2024-06-26T16:12:22.814220",
     "exception": false,
     "start_time": "2024-06-26T16:12:20.031405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to GeoDataFrame\n",
      "Time to execute: 0.05\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data['x'], data['y']))\n",
    "print(\"Converted to GeoDataFrame\")\n",
    "end_time = time.time()\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564171d",
   "metadata": {
    "papermill": {
     "duration": 0.004505,
     "end_time": "2024-06-26T16:12:22.853589",
     "exception": false,
     "start_time": "2024-06-26T16:12:22.849084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create and Initialize Raster\n",
    "\n",
    "Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d205eac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:22.862273Z",
     "iopub.status.busy": "2024-06-26T16:12:22.861751Z",
     "iopub.status.idle": "2024-06-26T16:12:23.017574Z",
     "shell.execute_reply": "2024-06-26T16:12:23.016029Z"
    },
    "papermill": {
     "duration": 0.162849,
     "end_time": "2024-06-26T16:12:23.020616",
     "exception": false,
     "start_time": "2024-06-26T16:12:22.857767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster metadata prepared\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster initialized\n",
      "Time to execute: 0.00\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#convert arc seconds to decimal degrees (to determine pixel size)\n",
    "pixel_size = 15 / 3600 \n",
    "\n",
    "#Retrieve the minimum and maximum x (longitude) and y (latitude) bounds to determine geographical extent of data\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "#Calcuate width and heigth of raster based on min max values\n",
    "width = int(np.ceil((xmax - xmin) / pixel_size))\n",
    "height = int(np.ceil((ymax - ymin) / pixel_size))\n",
    "\n",
    "#define affine transformation parameters (linear mapping method)\n",
    "transform = from_origin(xmin, ymax, pixel_size, pixel_size)\n",
    "\n",
    "#prepare raster meta data\n",
    "raster_meta = {\n",
    "    'driver': 'GTiff',\n",
    "    'count': 1,\n",
    "    'dtype': 'int32',\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'crs': 'EPSG:4326',\n",
    "    'transform': transform,\n",
    "    'nodata': -999  # Explicitly setting nodata value\n",
    "}\n",
    "print(\"Raster metadata prepared\")\n",
    "\n",
    "# Initialize raster (create an empty raster with the specified dimensions and data type)\n",
    "with rasterio.open('haslight.tif', 'w+', **raster_meta) as raster_data:\n",
    "    raster_data.write_band(1, np.zeros((height, width), dtype='int32'))\n",
    "    print(\"Raster initialized\")\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19e731",
   "metadata": {
    "papermill": {
     "duration": 0.003809,
     "end_time": "2024-06-26T16:12:23.027491",
     "exception": false,
     "start_time": "2024-06-26T16:12:23.023682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Burn 'haslight' Values into Raster\n",
    "\n",
    "Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bc9d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:23.035098Z",
     "iopub.status.busy": "2024-06-26T16:12:23.034544Z",
     "iopub.status.idle": "2024-06-26T16:12:23.704392Z",
     "shell.execute_reply": "2024-06-26T16:12:23.703699Z"
    },
    "papermill": {
     "duration": 0.677047,
     "end_time": "2024-06-26T16:12:23.707199",
     "exception": false,
     "start_time": "2024-06-26T16:12:23.030152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some points are out of bounds and will not be included in the raster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haslight values burnt into the raster\n",
      "Time to execute: 0.01\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Update the raster with the values from the GeoDataFrame\n",
    "\n",
    "with rasterio.open('haslight.tif', 'r+') as raster_data:\n",
    "    # Prepare to burn the 'haslight' values into the raster\n",
    "    row_indices = np.floor((ymax - gdf['y']) / pixel_size).astype(int) #calculate row indices of gdf points based on y-coordinates\n",
    "    col_indices = np.floor((gdf['x'] - xmin) / pixel_size).astype(int) #calculate column indices based on x-coordinates\n",
    "    \n",
    "    # Check if any indices are out of bounds\n",
    "    valid_rows = (row_indices >= 0) & (row_indices < height)\n",
    "    valid_cols = (col_indices >= 0) & (col_indices < width)\n",
    "    valid = valid_rows & valid_cols\n",
    "\n",
    "    if not valid.all():\n",
    "        print(\"Warning: Some points are out of bounds and will not be included in the raster.\")\n",
    "\n",
    "    # Create a full array of the raster and update it\n",
    "    raster_array = raster_data.read(1)\n",
    "    np.add.at(raster_array, (row_indices[valid], col_indices[valid]), gdf['haslight'][valid]) #adds 'haslight' values from gdf to appropriate locations in raster_array\n",
    "    raster_data.write_band(1, raster_array) #writes the updated raster_array back\n",
    "    print(\"Haslight values burnt into the raster\")\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6f934",
   "metadata": {
    "papermill": {
     "duration": 0.005381,
     "end_time": "2024-06-26T16:12:23.748726",
     "exception": false,
     "start_time": "2024-06-26T16:12:23.743345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Shapefile\n",
    "\n",
    "This takes some time, depending on file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4b52f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:12:23.759639Z",
     "iopub.status.busy": "2024-06-26T16:12:23.758909Z",
     "iopub.status.idle": "2024-06-26T16:14:16.112454Z",
     "shell.execute_reply": "2024-06-26T16:14:16.111325Z"
    },
    "papermill": {
     "duration": 112.364734,
     "end_time": "2024-06-26T16:14:16.117386",
     "exception": false,
     "start_time": "2024-06-26T16:12:23.752652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "grid3_AGO/GRID3_AGO_-_Settlement_Extents_v1.1.shp\n",
      "...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers for each settlement type before geometries applied:\n",
      "type\n",
      "Hamlet                   563715\n",
      "Small Settlement Area     18132\n",
      "Built-up Area               197\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet: 0 geometries removed (0.00%)\n",
      "Small Settlement Area: 0 geometries removed (0.00%)\n",
      "Built-up Area: 0 geometries removed (0.00%)\n",
      "Invalid and empty geometries removed\n",
      "Numbers for each settlement type AFTER geometries applied:\n",
      "type\n",
      "Hamlet                   563715\n",
      "Small Settlement Area     18132\n",
      "Built-up Area               197\n",
      "Name: count, dtype: int64\n",
      "Time to execute: 1.87 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Go to the grid3 subfolder\n",
    "grid3_folder = 'grid3_' + countrycode\n",
    "\n",
    "# Find the shapefile in the directory\n",
    "shapefile = None\n",
    "\n",
    "#for countrynames with several words\n",
    "first_word_countryname = countryname.split()[0]\n",
    "\n",
    "# shapefile should contain the ending .shp, and the countrycode or countryname (at least the first word), as grid3 data tends to do\n",
    "for file in os.listdir(grid3_folder):\n",
    "    if file.endswith('.shp') and (countrycode in file or first_word_countryname in file):\n",
    "        shapefile = file\n",
    "        break\n",
    "\n",
    "# Check if the shapefile was found and if it contains the countrycode\n",
    "if shapefile is None:\n",
    "    print('No shapefile found in the directory ending with .shp')\n",
    "\n",
    "# Print the shapefile path\n",
    "shapefile_path = os.path.join(grid3_folder, shapefile)\n",
    "\n",
    "print(\"Loading\")\n",
    "print(shapefile_path)\n",
    "print(\"...\")\n",
    "\n",
    "settlements = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Ensure spelling is Built-up and not Built-Up (e.g. Kenya data)\n",
    "settlements['type'] = settlements['type'].replace('Built-Up Area', 'Built-up Area')\n",
    "\n",
    "#checking total of settlements per type\n",
    "settlement_type_counts = settlements['type'].value_counts()\n",
    "print(\"Numbers for each settlement type before geometries applied:\")\n",
    "print(settlement_type_counts)\n",
    "\n",
    "# Count the number of geometries for each settlement type before removal\n",
    "type_counts_before = settlements['type'].value_counts()\n",
    "\n",
    "# Ensure all geometries are valid\n",
    "settlements['geometry'] = settlements['geometry'].astype(object).apply(lambda geom: geom if geom.is_valid else geom.buffer(0))\n",
    "\n",
    "# Remove empty geometries\n",
    "settlements = settlements[~settlements['geometry'].is_empty]\n",
    "\n",
    "# Count the number of geometries for each settlement type after removal\n",
    "type_counts_after = settlements['type'].value_counts()\n",
    "\n",
    "# Calculate the number and proportion of geometries removed for each settlement type\n",
    "for settlement_type in type_counts_before.index:\n",
    "    count_before = type_counts_before[settlement_type]\n",
    "    count_after = type_counts_after.get(settlement_type, 0)\n",
    "    count_removed = count_before - count_after\n",
    "    proportion_removed = count_removed / count_before\n",
    "    print(f\"{settlement_type}: {count_removed} geometries removed ({proportion_removed:.2%})\")\n",
    "print(\"Invalid and empty geometries removed\")\n",
    "print(\"Numbers for each settlement type AFTER geometries applied:\")\n",
    "settlement_type_counts = settlements['type'].value_counts()\n",
    "print(settlement_type_counts)\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d289d9",
   "metadata": {
    "papermill": {
     "duration": 0.00426,
     "end_time": "2024-06-26T16:14:16.127651",
     "exception": false,
     "start_time": "2024-06-26T16:14:16.123391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculate zonal statistics\n",
    "\n",
    "In this step, simply check if there is NTL (0/1), then for each settlement calculate what percentage of the polygon has NTL. \n",
    "\n",
    "This cell takes some time, with Sudan, around 10min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef34f92b-b5e2-411d-88af-e922456cd64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:14:16.136292Z",
     "iopub.status.busy": "2024-06-26T16:14:16.136079Z",
     "iopub.status.idle": "2024-06-26T16:17:33.996968Z",
     "shell.execute_reply": "2024-06-26T16:17:33.996055Z"
    },
    "papermill": {
     "duration": 197.871879,
     "end_time": "2024-06-26T16:17:34.003195",
     "exception": false,
     "start_time": "2024-06-26T16:14:16.131316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted percentages added to GeoDataFrame\n",
      "Execution time: 3.2975780804951986 minutes\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "from exactextract import exact_extract\n",
    "import time\n",
    "\n",
    "# Start time for execution time calculation\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the path to your raster data\n",
    "raster_path = 'haslight.tif'\n",
    "\n",
    "# Open the raster and convert it to binary (has light or has no light)\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(1)  # Read the first band\n",
    "    binary_raster_data = (raster_data > 0).astype(int)  # Convert to binary\n",
    "\n",
    "    # Write the binary raster to a new file (optional, can also be done in-memory)\n",
    "    binary_raster_path = 'binary_haslight.tif'\n",
    "    profile = src.profile\n",
    "    with rasterio.open(binary_raster_path, 'w', **profile) as dst:\n",
    "        dst.write(binary_raster_data, 1)\n",
    "\n",
    "# Perform the exact extraction using the binary raster\n",
    "settlements_updated = settlements.copy()\n",
    "results = exact_extract(binary_raster_path, settlements, [\"mean\"])\n",
    "\n",
    "# Add the weighted mean light coverage to the settlements GeoDataFrame\n",
    "settlements_updated['NTL_weighted_percentage'] = [feature['properties']['mean'] * 100 for feature in results]\n",
    "print(\"Weighted percentages added to GeoDataFrame\")\n",
    "\n",
    "# Calculate the execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf352a",
   "metadata": {
    "papermill": {
     "duration": 0.004389,
     "end_time": "2024-06-26T16:17:34.011859",
     "exception": false,
     "start_time": "2024-06-26T16:17:34.007470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be29291-bef7-4d0b-876e-2627b5fab348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:17:34.025032Z",
     "iopub.status.busy": "2024-06-26T16:17:34.024831Z",
     "iopub.status.idle": "2024-06-26T16:17:38.708546Z",
     "shell.execute_reply": "2024-06-26T16:17:38.706680Z"
    },
    "papermill": {
     "duration": 4.695324,
     "end_time": "2024-06-26T16:17:38.711800",
     "exception": false,
     "start_time": "2024-06-26T16:17:34.016476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved, all done.\n",
      "Time to execute: 0.08 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "csv_name = countrycode + '_grid3_with_ntl_percentage.csv'\n",
    "settlements_updated.drop(columns=['geometry']).to_csv(csv_name, index=False)\n",
    "print(\"CSV saved, all done.\")\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0423a4",
   "metadata": {
    "papermill": {
     "duration": 0.005199,
     "end_time": "2024-06-26T16:17:38.752578",
     "exception": false,
     "start_time": "2024-06-26T16:17:38.747379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculate key stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af18db85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:17:38.762706Z",
     "iopub.status.busy": "2024-06-26T16:17:38.762263Z",
     "iopub.status.idle": "2024-06-26T16:17:40.032506Z",
     "shell.execute_reply": "2024-06-26T16:17:40.030737Z"
    },
    "papermill": {
     "duration": 1.278726,
     "end_time": "2024-06-26T16:17:40.035761",
     "exception": false,
     "start_time": "2024-06-26T16:17:38.757035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKey stats Angolan\u001b[0m\n",
      "Something wrong with 0 entries\n",
      " \n",
      "\u001b[1mOverview all settlements\u001b[0m\n",
      "Proportion nighttime light: 1.54%\n",
      "Proportion monitorable: 1.25%\n",
      " \n",
      "\u001b[1mOverview built-up areas\u001b[0m\n",
      "Total number of built-up areas: 197\n",
      "Proportion nighttime light > 0: 67.01%\n",
      "Median NTL for settlements with any NTL: 6499.78%\n",
      "Proportion monitorable: 45.18%\n",
      " \n",
      "\u001b[1mOverview small settlements\u001b[0m\n",
      "Total number of small settlement areas: 18132\n",
      "Proportion nighttime light: 4.50%\n",
      "Median NTL for settlements with any NTL: 6445.31%\n",
      "Proportion monitorable: 2.88%\n",
      " \n",
      "\u001b[1mOverview hamlets\u001b[0m\n",
      "Total number of hamlets: 563715\n",
      "Proportion nighttime light: 1.42%\n",
      "Median NTL for settlements with any NTL: 10000.00%\n",
      "Proportion monitorable: 1.19%\n",
      " \n",
      "\u001b[1mOverview monitorable population\u001b[0m\n",
      "Proportion of population that is monitorable (living in settlements with more than 50% NTL): 67.27%\n",
      "Proportion of population that lives in settlements with any NTL): 70.84%\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the CSV file\n",
    "df = pd.read_csv(csv_name)\n",
    "\n",
    "print(f\"\\033[1mKey stats {countryname}n\\033[0m\")\n",
    "\n",
    "# Calculate 'something_wrong' (should be 0)\n",
    "#something_wrong = (df['NTL_weighted_percentage'] > 100).sum()\n",
    "#print(f\"Number of rows where there is something wrong with 'NTL_weighted_percentage': {something_wrong}\")\n",
    "something_wrong = (df['NTL_weighted_percentage'] > 100).sum()\n",
    "print(f\"Something wrong with {something_wrong} entries\")\n",
    "      \n",
    "print(\" \")\n",
    "# Calculate 'settl_ntl_perc'\n",
    "print(\"\\033[1mOverview all settlements\\033[0m\")\n",
    "settl_ntl_perc = (df['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {settl_ntl_perc:.2%}\")\n",
    "settl_monit_perc = (df['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {settl_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview built-up areas\\033[0m\")\n",
    "# Calculate 'built_up_perc'\n",
    "df_built_up = df[df['type'] == 'Built-up Area']\n",
    "#Get the total number of built-up areas; shape gives tuple of dimensions\n",
    "print(f\"Total number of built-up areas: {df_built_up.shape[0]}\")\n",
    "built_ntl_perc = (df_built_up['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light > 0: {built_ntl_perc:.2%}\")\n",
    "\n",
    "#median ntl coverage of all the settlements that have at least some NTL\n",
    "anyntl = df_built_up[df_built_up['NTL_weighted_percentage'] > 0]\n",
    "built_median_any = anyntl['NTL_weighted_percentage'].median()\n",
    "print(f\"Median NTL for settlements with any NTL: {built_median_any:.2%}\")\n",
    "built_monit_perc = (df_built_up['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {built_monit_perc:.2%}\")\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview small settlements\\033[0m\")\n",
    "# Calculate 'small_settl_perc'\n",
    "df_small_set = df[df['type'] == 'Small Settlement Area']\n",
    "print(f\"Total number of small settlement areas: {df_small_set.shape[0]}\")\n",
    "smallset_ntl_perc = (df_small_set['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {smallset_ntl_perc:.2%}\")\n",
    "#median ntl coverage of all the settlements that have at least some NTL\n",
    "anyntl = df_small_set[df_small_set['NTL_weighted_percentage'] > 0]\n",
    "small_median_any = anyntl['NTL_weighted_percentage'].median()\n",
    "print(f\"Median NTL for settlements with any NTL: {small_median_any:.2%}\")\n",
    "smallset_monit_perc = (df_small_set['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {smallset_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview hamlets\\033[0m\")\n",
    "# Calculate 'hamlets_perc'\n",
    "df_hamlet = df[df['type'] == 'Hamlet']\n",
    "print(f\"Total number of hamlets: {df_hamlet.shape[0]}\")\n",
    "haml_ntl_perc = (df_hamlet['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {haml_ntl_perc:.2%}\")\n",
    "#median ntl coverage of all the settlements that have at least some NTL\n",
    "anyntl = df_hamlet[df_hamlet['NTL_weighted_percentage'] > 0]\n",
    "hamlet_median_any = anyntl['NTL_weighted_percentage'].median()\n",
    "print(f\"Median NTL for settlements with any NTL: {hamlet_median_any:.2%}\")\n",
    "haml_monit_perc = (df_hamlet['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {haml_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview monitorable population\\033[0m\")\n",
    "#settlements with more than 50% ntl\n",
    "df_mont = df[df['NTL_weighted_percentage'] > 50]\n",
    "monitorable_pop = df_mont['pop_un_adj'].sum()/df['pop_un_adj'].sum()\n",
    "\n",
    "print(f\"Proportion of population that is monitorable (living in settlements with more than 50% NTL): {monitorable_pop:.2%}\")\n",
    "\n",
    "#settlements with any ntl\n",
    "df_anyntl = df[df['NTL_weighted_percentage'] > 0]\n",
    "pop_anyntl = df_anyntl['pop_un_adj'].sum()/df['pop_un_adj'].sum()\n",
    "\n",
    "print(f\"Proportion of population that lives in settlements with any NTL): {pop_anyntl:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19da56-6c0d-4bd3-bed9-d0804a39c363",
   "metadata": {
    "papermill": {
     "duration": 0.005945,
     "end_time": "2024-06-26T16:17:40.081373",
     "exception": false,
     "start_time": "2024-06-26T16:17:40.075428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Calculate 80% threshold to have any nighttime light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efffe7a3-f798-4a07-99c0-13a65071aef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:17:40.093219Z",
     "iopub.status.busy": "2024-06-26T16:17:40.092609Z",
     "iopub.status.idle": "2024-06-26T16:17:43.533324Z",
     "shell.execute_reply": "2024-06-26T16:17:43.532402Z"
    },
    "papermill": {
     "duration": 3.448486,
     "end_time": "2024-06-26T16:17:43.535735",
     "exception": false,
     "start_time": "2024-06-26T16:17:40.087249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.077735\n",
      "         Iterations 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                any_ntl   No. Observations:               581323\n",
      "Model:                          Logit   Df Residuals:                   581321\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 26 Jun 2024   Pseudo R-squ.:                 0.02165\n",
      "Time:                        18:17:43   Log-Likelihood:                -45189.\n",
      "converged:                       True   LL-Null:                       -46189.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.2109      0.011   -385.949      0.000      -4.232      -4.190\n",
      "pop_un_adj     0.0012   4.12e-05     28.508      0.000       0.001       0.001\n",
      "==============================================================================\n",
      "The population threshold for 80% likelihood of having any NTL is approximately 14487.890400624012\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(csv_name)\n",
    "\n",
    "# Create the 'any ntl' column, which just looks at whether there is any NTL in the settlement\n",
    "df['any_ntl'] = df['NTL_weighted_percentage'] > 0\n",
    "\n",
    "# Check for missing or infinite values in 'pop_un_adj'\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "# Drop rows with missing values\n",
    "df = df.dropna(subset=['pop_un_adj'])\n",
    "\n",
    "# Ensure there is variation in 'pop_un_adj' and 'any_ntl'\n",
    "if df['pop_un_adj'].nunique() <= 1 or df['any_ntl'].nunique() <= 1:\n",
    "    raise ValueError(\"Insufficient variation in 'pop_un_adj' or 'any_ntl'\")\n",
    "\n",
    "# Prepare the data for logistic regression\n",
    "X = df['pop_un_adj']\n",
    "y = df['any_ntl'].astype(int)  # Convert boolean to int (0 or 1)\n",
    "\n",
    "# Add a small constant to avoid singular matrix\n",
    "X = X + 1e-6\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n",
    "\n",
    "# Define the function to calculate the probability\n",
    "def calculate_probability(population, model):\n",
    "    logit = model.params['const'] + model.params['pop_un_adj'] * population\n",
    "    return 1 / (1 + np.exp(-logit))\n",
    "\n",
    "# Find the population threshold for 80% probability\n",
    "population_range = np.linspace(df['pop_un_adj'].min(), df['pop_un_adj'].max(), 1000)\n",
    "probabilities = [calculate_probability(pop, result) for pop in population_range]\n",
    "\n",
    "# Find the population where the probability is closest to 0.8\n",
    "threshold_anyntl = population_range[np.argmin(np.abs(np.array(probabilities) - 0.8))]\n",
    "print(f\"The population threshold for 80% likelihood of having any NTL is approximately {threshold_anyntl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0e501-7883-4ff2-bd28-2f7e4dd40ef6",
   "metadata": {
    "papermill": {
     "duration": 0.004896,
     "end_time": "2024-06-26T16:17:43.574628",
     "exception": false,
     "start_time": "2024-06-26T16:17:43.569732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# save stats to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dafea3cc-6548-4053-baf6-44f210328350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:17:43.586938Z",
     "iopub.status.busy": "2024-06-26T16:17:43.586504Z",
     "iopub.status.idle": "2024-06-26T16:17:43.595891Z",
     "shell.execute_reply": "2024-06-26T16:17:43.595263Z"
    },
    "papermill": {
     "duration": 0.019179,
     "end_time": "2024-06-26T16:17:43.598166",
     "exception": false,
     "start_time": "2024-06-26T16:17:43.578987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries\n",
    "stats = [\n",
    "    {\"type\": \"Error\", \"what\": \"Settlements with over 100% NTL\", \"value\": something_wrong},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Total number\", \"value\": len(df)},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Proportion NTL\", \"value\": f\"{settl_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Proportion monitorable\", \"value\": f\"{settl_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Total number\", \"value\": df_built_up.shape[0]},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Proportion NTL\", \"value\": f\"{built_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Proportion monitorable\", \"value\": f\"{built_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Total number\", \"value\": df_small_set.shape[0]},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Proportion NTL\", \"value\": f\"{smallset_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Proportion monitorable\", \"value\": f\"{smallset_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Total number\", \"value\": df_hamlet.shape[0]},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Proportion NTL\", \"value\": f\"{haml_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Proportion monitorable\", \"value\": f\"{haml_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Population\", \"what\": \"Proportion living in settlements with any NTL\", \"value\": f\"{pop_anyntl:.2%}\"},\n",
    "    {\"type\": \"Population\", \"what\": \"Proportion living in monitorable settlements\", \"value\": f\"{monitorable_pop:.2%}\"},\n",
    "    {\"type\": \"Threshold NTL\", \"what\": \"Threshold 0.8 likelihood of any NTL in a settlement\", \"value\": f\"{threshold_anyntl}\"},\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df_output = pd.DataFrame(stats)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = 'overview_key_stats.csv'\n",
    "df_output.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Data saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 330.840352,
   "end_time": "2024-06-26T16:17:46.052733",
   "environment_variables": {},
   "exception": null,
   "input_path": "0_country-level-analysis-parametrized.ipynb",
   "output_path": "output_AGO.ipynb",
   "parameters": {
    "countrycode": "AGO",
    "countryname": "Angola"
   },
   "start_time": "2024-06-26T16:12:15.212381",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}