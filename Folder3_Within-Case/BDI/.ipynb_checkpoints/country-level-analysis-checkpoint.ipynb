{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79a9fe1-ec0d-43de-9dc8-490071ccde41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set\n"
     ]
    }
   ],
   "source": [
    "# Setting parameters, replace with defaults when using a master notebook\n",
    "\n",
    "countrycode = 'BDI'\n",
    "countryname = 'Burundi'\n",
    "print(\"Parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686584ea",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0e1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.mask import mask\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "from exactextract import exact_extract\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48cb26",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca5a914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Binary created\n",
      "Time to execute: 0.00\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load the CSV data\n",
    "csv_file = countrycode + '_ntl_pop.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# Create a binary 'haslight' column and drop the 'ntl' and 'pop' columns\n",
    "data['haslight'] = (data['ntl'] > 0).astype(int)\n",
    "data.drop(columns=['ntl', 'pop'], inplace=True)\n",
    "print(\"Binary created\")\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae648d",
   "metadata": {},
   "source": [
    "# Convert DataFrame to GeoDataFrame\n",
    "\n",
    "Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7de8e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to GeoDataFrame\n",
      "Time to execute: 0.00\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data['x'], data['y']))\n",
    "print(\"Converted to GeoDataFrame\")\n",
    "end_time = time.time()\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564171d",
   "metadata": {},
   "source": [
    "# Create and Initialize Raster\n",
    "\n",
    "Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d205eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster metadata prepared\n",
      "Raster initialized\n",
      "Time to execute: 0.00\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#convert arc seconds to decimal degrees (to determine pixel size)\n",
    "pixel_size = 15 / 3600 \n",
    "\n",
    "#Retrieve the minimum and maximum x (longitude) and y (latitude) bounds to determine geographical extent of data\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "#Calcuate width and heigth of raster based on min max values\n",
    "width = int(np.ceil((xmax - xmin) / pixel_size))\n",
    "height = int(np.ceil((ymax - ymin) / pixel_size))\n",
    "\n",
    "#define affine transformation parameters (linear mapping method)\n",
    "transform = from_origin(xmin, ymax, pixel_size, pixel_size)\n",
    "\n",
    "#prepare raster meta data\n",
    "raster_meta = {\n",
    "    'driver': 'GTiff',\n",
    "    'count': 1,\n",
    "    'dtype': 'int32',\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'crs': 'EPSG:4326',\n",
    "    'transform': transform,\n",
    "    'nodata': -999  # Explicitly setting nodata value\n",
    "}\n",
    "print(\"Raster metadata prepared\")\n",
    "\n",
    "# Initialize raster (create an empty raster with the specified dimensions and data type)\n",
    "with rasterio.open('haslight.tif', 'w+', **raster_meta) as raster_data:\n",
    "    raster_data.write_band(1, np.zeros((height, width), dtype='int32'))\n",
    "    print(\"Raster initialized\")\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19e731",
   "metadata": {},
   "source": [
    "# Burn 'haslight' Values into Raster\n",
    "\n",
    "Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82bc9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some points are out of bounds and will not be included in the raster.\n",
      "Haslight values burnt into the raster\n",
      "Time to execute: 0.00\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Update the raster with the values from the GeoDataFrame\n",
    "\n",
    "with rasterio.open('haslight.tif', 'r+') as raster_data:\n",
    "    # Prepare to burn the 'haslight' values into the raster\n",
    "    row_indices = np.floor((ymax - gdf['y']) / pixel_size).astype(int) #calculate row indices of gdf points based on y-coordinates\n",
    "    col_indices = np.floor((gdf['x'] - xmin) / pixel_size).astype(int) #calculate column indices based on x-coordinates\n",
    "    \n",
    "    # Check if any indices are out of bounds\n",
    "    valid_rows = (row_indices >= 0) & (row_indices < height)\n",
    "    valid_cols = (col_indices >= 0) & (col_indices < width)\n",
    "    valid = valid_rows & valid_cols\n",
    "\n",
    "    if not valid.all():\n",
    "        print(\"Warning: Some points are out of bounds and will not be included in the raster.\")\n",
    "\n",
    "    # Create a full array of the raster and update it\n",
    "    raster_array = raster_data.read(1)\n",
    "    np.add.at(raster_array, (row_indices[valid], col_indices[valid]), gdf['haslight'][valid]) #adds 'haslight' values from gdf to appropriate locations in raster_array\n",
    "    raster_data.write_band(1, raster_array) #writes the updated raster_array back\n",
    "    print(\"Haslight values burnt into the raster\")\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6f934",
   "metadata": {},
   "source": [
    "# Load Shapefile\n",
    "\n",
    "This takes some time, depending on file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4b52f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No shapefile found in the directory ending with .shp\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo shapefile found in the directory ending with .shp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Print the shapefile path\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m shapefile_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid3_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapefile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(shapefile_path)\n\u001b[1;32m     23\u001b[0m settlements \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(shapefile_path)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ntl_virt2/lib/python3.9/posixpath.py:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     88\u001b[0m             path \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sep \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mBytesWarning\u001b[39;00m):\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mgenericpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_arg_types\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjoin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ntl_virt2/lib/python3.9/genericpath.py:152\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n\u001b[1;32m    150\u001b[0m         hasbytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() argument must be str, bytes, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    153\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike object, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hasstr \u001b[38;5;129;01mand\u001b[39;00m hasbytes:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt mix strings and bytes in path components\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Go to the grid3 subfolder\n",
    "grid3_folder = 'grid3_' + countrycode\n",
    "\n",
    "# Find the shapefile in the directory\n",
    "shapefile = None\n",
    "\n",
    "for file in os.listdir(grid3_folder):\n",
    "    if file.endswith('.shp') and (countrycode in file or countryname in file):\n",
    "        shapefile = file\n",
    "        break\n",
    "\n",
    "# Check if the shapefile was found and if it contains the countrycode\n",
    "if shapefile is None:\n",
    "    print('No shapefile found in the directory ending with .shp')\n",
    "\n",
    "# Print the shapefile path\n",
    "shapefile_path = os.path.join(grid3_folder, shapefile)\n",
    "\n",
    "print(shapefile_path)\n",
    "\n",
    "settlements = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Ensure all geometries are valid\n",
    "settlements['geometry'] = settlements['geometry'].astype(object).apply(lambda geom: geom if geom.is_valid else geom.buffer(0))\n",
    "\n",
    "# Remove empty geometries\n",
    "settlements = settlements[~settlements['geometry'].is_empty]\n",
    "\n",
    "print(\"Invalid and empty geometries removed\")\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d289d9",
   "metadata": {},
   "source": [
    "# Calculate zonal statistics\n",
    "\n",
    "In this step, simply check if there is NTL (0/1), then for each settlement calculate what percentage of the polygon has NTL. \n",
    "\n",
    "This cell takes some time, with Sudan, around 10min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34f92b-b5e2-411d-88af-e922456cd64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "from exactextract import exact_extract\n",
    "import time\n",
    "\n",
    "# Start time for execution time calculation\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the path to your raster data\n",
    "raster_path = 'haslight.tif'\n",
    "\n",
    "# Open the raster and convert it to binary (has light or has no light)\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(1)  # Read the first band\n",
    "    binary_raster_data = (raster_data > 0).astype(int)  # Convert to binary\n",
    "\n",
    "    # Write the binary raster to a new file (optional, can also be done in-memory)\n",
    "    binary_raster_path = 'binary_haslight.tif'\n",
    "    profile = src.profile\n",
    "    with rasterio.open(binary_raster_path, 'w', **profile) as dst:\n",
    "        dst.write(binary_raster_data, 1)\n",
    "\n",
    "# Perform the exact extraction using the binary raster\n",
    "settlements_updated = settlements.copy()\n",
    "results = exact_extract(binary_raster_path, settlements, [\"mean\"])\n",
    "\n",
    "# Add the weighted mean light coverage to the settlements GeoDataFrame\n",
    "settlements_updated['NTL_weighted_percentage'] = [feature['properties']['mean'] * 100 for feature in results]\n",
    "print(\"Weighted percentages added to GeoDataFrame\")\n",
    "\n",
    "# Calculate the execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time/60} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf352a",
   "metadata": {},
   "source": [
    "# Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5863f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#create subfolder if it doesn't exist already\n",
    "output_dir = 'country-level'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save as CSV without geometry\n",
    "output_file = os.path.join(output_dir, 'sdngrid3_with_ntl_percentage.csv')\n",
    "settlements_updated .drop(columns=['geometry']).to_csv('sdngrid3_with_ntl_percentage.csv', index=False)\n",
    "print(\"CSV saved, all done.\")\n",
    "\n",
    "print(f\"Time to execute: {((time.time() - start_time)/60):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0423a4",
   "metadata": {},
   "source": [
    "# Calculate key stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('sdngrid3_with_ntl_percentage.csv')\n",
    "\n",
    "print(\"\\033[1mKey stats Sudan\\033[0m\")\n",
    "\n",
    "# Calculate 'something_wrong' (should be 0)\n",
    "#something_wrong = (df['NTL_weighted_percentage'] > 100).sum()\n",
    "#print(f\"Number of rows where there is something wrong with 'NTL_weighted_percentage': {something_wrong}\")\n",
    "something_wrong = (df['NTL_weighted_percentage'] > 100).sum()\n",
    "print(f\"Something wrong with {something_wrong} entries\")\n",
    "      \n",
    "print(\" \")\n",
    "# Calculate 'settl_ntl_perc'\n",
    "print(\"\\033[1mOverview all settlements\\033[0m\")\n",
    "settl_ntl_perc = (df['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {settl_ntl_perc:.2%}\")\n",
    "settl_monit_perc = (df['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {settl_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview built-up areas\\033[0m\")\n",
    "# Calculate 'built_up_perc'\n",
    "df_built_up = df[df['type'] == 'Built-up Area']\n",
    "#Get the total number of built-up areas; shape gives tuple of dimensions\n",
    "print(f\"Total number of built-up areas: {df_built_up.shape[0]}\")\n",
    "built_ntl_perc = (df_built_up['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light > 0: {built_ntl_perc:.2%}\")\n",
    "built_monit_perc = (df_built_up['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {built_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview small settlements\\033[0m\")\n",
    "# Calculate 'small_settl_perc'\n",
    "df_small_set = df[df['type'] == 'Small Settlement Area']\n",
    "print(f\"Total number of small settlement areas: {df_small_set.shape[0]}\")\n",
    "smallset_ntl_perc = (df_small_set['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {smallset_ntl_perc:.2%}\")\n",
    "smallset_monit_perc = (df_small_set['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion monitorable: {smallset_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview hamlets\\033[0m\")\n",
    "# Calculate 'hamlets_perc'\n",
    "df_hamlet = df[df['type'] == 'Hamlet']\n",
    "print(f\"Total number of hamlets: {df_hamlet.shape[0]}\")\n",
    "haml_ntl_perc = (df_hamlet['NTL_weighted_percentage'] > 0).mean()\n",
    "print(f\"Proportion nighttime light: {haml_ntl_perc:.2%}\")\n",
    "haml_monit_perc = (df_hamlet['NTL_weighted_percentage'] > 50).mean()\n",
    "print(f\"Proportion nighttime light: {haml_monit_perc:.2%}\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"\\033[1mOverview monitorable population\\033[0m\")\n",
    "#settlements with more than 50% ntl\n",
    "df_mont = df[df['NTL_weighted_percentage'] > 50]\n",
    "monitorable_pop = df_mont['pop_un_adj'].sum()/df['pop_un_adj'].sum()\n",
    "print(f\"Proportion of population that is monitorable (living in settlements with more than 50% NTL): {monitorable_pop:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0e501-7883-4ff2-bd28-2f7e4dd40ef6",
   "metadata": {},
   "source": [
    "save stats to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafea3cc-6548-4053-baf6-44f210328350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries\n",
    "stats = [\n",
    "    {\"type\": \"Error\", \"what\": \"Settlements with over 100% NTL\", \"value\": something_wrong},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Total number\", \"value\": len(df)},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Proportion NTL\", \"value\": f\"{settl_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"All settlements\", \"what\": \"Proportion monitorable\", \"value\": f\"{settl_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Total number\", \"value\": df_built_up.shape[0]},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Proportion NTL\", \"value\": f\"{built_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Built-up\", \"what\": \"Proportion monitorable\", \"value\": f\"{built_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Total number\", \"value\": df_small_set.shape[0]},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Proportion NTL\", \"value\": f\"{smallset_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Small settlements\", \"what\": \"Proportion monitorable\", \"value\": f\"{smallset_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Total number\", \"value\": df_hamlet.shape[0]},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Proportion NTL\", \"value\": f\"{haml_ntl_perc:.2%}\"},\n",
    "    {\"type\": \"Hamlets\", \"what\": \"Proportion monitorable\", \"value\": f\"{haml_monit_perc:.2%}\"},\n",
    "    {\"type\": \"Population\", \"what\": \"Proportion living in monitorable settlements\", \"value\": f\"{monitorable_pop:.2%}\"},\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df_output = pd.DataFrame(stats)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_dir = 'country-level'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'overview_key_stats.csv')\n",
    "df_output.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Data saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
